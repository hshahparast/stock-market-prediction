{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, the performance of 3 deep nn on time series data of stock markets are compared:\n",
        "* RNN\n",
        "* LSTM \n",
        "* GRU"
      ],
      "metadata": {
        "id": "vml2HCekoa5Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KzOTdKHrdU-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from io import open\n",
        "import csv\n",
        "from math import ceil, floor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "wyt4nLOVrw95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fileName = 'sample_data/data.csv'\n",
        "data = pd.read_csv(fileName)\n",
        "data = data.iloc[:,0:1].values\n",
        "sc = MinMaxScaler()\n",
        "data = sc.fit_transform(data)\n",
        "numSamples = len(data)"
      ],
      "metadata": {
        "id": "t8Z3jlGyr42R"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class: RNN\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self,input_dim,hidden_dim,output_dim,n_layers):\n",
        "    super(RNN,self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.rnn = nn.RNN(input_dim, hidden_dim, n_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "  def forward(self,x,hidden):\n",
        "     batch_size = x.size(0)\n",
        "     # RNN outputs\n",
        "     r_out, hidden = self.rnn(x, hidden)\n",
        "     # shape output to be (batch_size*seq_length, hidden_dim)\n",
        "     r_out = r_out.view(-1, self.hidden_dim)  \n",
        "     output = self.fc(r_out)\n",
        "     return output, hidden"
      ],
      "metadata": {
        "id": "H4zDU6HVsFgQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Class: LSTM\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.1):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        out, hidden = self.lstm(x, hidden)\n",
        "        out = self.fc(self.relu(out[:,-1]))\n",
        "        return out, hidden"
      ],
      "metadata": {
        "id": "xbyprBTysK0q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Class: GRU\n",
        "class GRU(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
        "        super(GRU, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        out, hidden = self.gru(x, hidden)\n",
        "        out = self.fc(self.relu(out[:,-1]))\n",
        "        return out, hidden\n",
        "    "
      ],
      "metadata": {
        "id": "N-53qpXzsWXW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "seq_length = 20\n",
        "input_dim=1 \n",
        "output_dim=1\n",
        "hidden_dim=32\n",
        "num_layers=1\n",
        "\n",
        "n_steps = floor(numSamples/seq_length)\n",
        "train_steps = int(n_steps * 0.7)\n",
        "test_steps = n_steps - train_steps\n",
        "print_every = 15"
      ],
      "metadata": {
        "id": "03x8UYfZsmfM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data, model_type=\"RNN\"):\n",
        "  hidden = None\n",
        "  if model_type == \"RNN\":\n",
        "      model = RNN(input_dim, hidden_dim, output_dim, num_layers)\n",
        "  elif model_type == \"LSTM\":\n",
        "      model = LSTM(input_dim, hidden_dim, output_dim, num_layers)\n",
        "  else:\n",
        "      model = GRU(input_dim, hidden_dim, output_dim, num_layers)\n",
        "  \n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "  model.to(device)  \n",
        "  model.train()\n",
        "  print(\"Starting Training of {} model\".format(model_type))    \n",
        "  for batch_i,step in enumerate(range(train_steps)):\n",
        "    firtInd = step*seq_length\n",
        "    lastInd = (step+1)*seq_length-1\n",
        "\n",
        "    x = data[firtInd:lastInd-1]\n",
        "    y = data[firtInd+1:lastInd]\n",
        "    # convert data into Tensors\n",
        "    x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension\n",
        "    y_tensor = torch.Tensor(y)\n",
        "\n",
        "    prediction, hidden = model(x_tensor, hidden)\n",
        "\n",
        "    if model_type == \"RNN\" or model_type == \"GRU\":\n",
        "      hidden = hidden.data\n",
        "    else:\n",
        "        hidden = tuple([e.data for e in hidden])\n",
        "\n",
        "    loss = criterion(prediction, y_tensor)\n",
        "    # zero gradients\n",
        "    optimizer.zero_grad()\n",
        "    # perform backprop and update weights\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Loss: ', loss.item())\n",
        "    # if batch_i%print_every == 0:        \n",
        "    #   print('Loss: ', loss.item())\n",
        "  return model"
      ],
      "metadata": {
        "id": "SUDrf7wCt8Pk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model):\n",
        "  loss_val = 0\n",
        "  model.eval()\n",
        "  hidden = None\n",
        "  for i,step in enumerate(range(test_steps)):\n",
        "    firtInd = step*seq_length\n",
        "    lastInd = (step+1)*seq_length-1\n",
        "\n",
        "    if step == test_steps:\n",
        "      lastInd = numSamples-1\n",
        "    x = data[firtInd:lastInd-1]\n",
        "    y = data[firtInd+1:lastInd]\n",
        "    # convert data into Tensors\n",
        "    x_tensor = torch.Tensor(x).unsqueeze(0) # unsqueeze gives a 1, batch_size dimension\n",
        "    y_tensor = torch.Tensor(y)\n",
        "\n",
        "    predict,h = model(x_tensor,hidden)\n",
        "    pred = torch.Tensor(predict.data[0])\n",
        "    # print(predict)\n",
        "    # print(y_tensor.size())\n",
        "    loss = criterion(pred, y_tensor)\n",
        "    loss_val = loss_val + loss\n",
        "  return loss_val/test_steps*100"
      ],
      "metadata": {
        "id": "IsReMZfdtwXx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelRNN = train(data, model_type=\"RNN\")"
      ],
      "metadata": {
        "id": "3gIzKLIg6h6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0958f69d-9602-4a71-be52-5ac582ec85f8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training of RNN model\n",
            "Loss:  0.008223269134759903\n",
            "Loss:  0.03255753591656685\n",
            "Loss:  0.004472177010029554\n",
            "Loss:  0.0017064898274838924\n",
            "Loss:  0.013760387897491455\n",
            "Loss:  0.025975549593567848\n",
            "Loss:  0.021533692255616188\n",
            "Loss:  0.012615122832357883\n",
            "Loss:  0.0008284252835437655\n",
            "Loss:  0.004725311882793903\n",
            "Loss:  0.02348748967051506\n",
            "Loss:  0.005808983463793993\n",
            "Loss:  0.12506693601608276\n",
            "Loss:  0.022986633703112602\n",
            "Loss:  0.00161171134095639\n",
            "Loss:  0.044263340532779694\n",
            "Loss:  0.07729709893465042\n",
            "Loss:  0.058353081345558167\n",
            "Loss:  0.02260841801762581\n",
            "Loss:  0.0003921735333278775\n",
            "Loss:  0.0017209808574989438\n",
            "Loss:  0.015011615119874477\n",
            "Loss:  0.05842477083206177\n",
            "Loss:  0.10018345713615417\n",
            "Loss:  0.09193155169487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTM = train(data, model_type=\"LSTM\")"
      ],
      "metadata": {
        "id": "8zvGWSuprslm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelGRU = train(data, model_type=\"GRU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR1oCtwAqoPN",
        "outputId": "a1856fa1-9b3a-4a84-9fdb-63cb6046055f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training of GRU model\n",
            "Loss:  0.010608199052512646\n",
            "Loss:  0.00012908682401757687\n",
            "Loss:  0.0034982110373675823\n",
            "Loss:  0.003956187050789595\n",
            "Loss:  0.004441886208951473\n",
            "Loss:  0.00782769825309515\n",
            "Loss:  0.007343041244894266\n",
            "Loss:  0.008513342589139938\n",
            "Loss:  0.0012439859565347433\n",
            "Loss:  0.018518198281526566\n",
            "Loss:  0.07626750320196152\n",
            "Loss:  0.11205262690782547\n",
            "Loss:  0.011209335178136826\n",
            "Loss:  0.0034012855030596256\n",
            "Loss:  0.03580725938081741\n",
            "Loss:  0.07558821141719818\n",
            "Loss:  0.37011078000068665\n",
            "Loss:  0.30629438161849976\n",
            "Loss:  0.20346802473068237\n",
            "Loss:  0.0927707627415657\n",
            "Loss:  0.056376561522483826\n",
            "Loss:  0.02185996063053608\n",
            "Loss:  0.0008381365332752466\n",
            "Loss:  0.019788645207881927\n",
            "Loss:  0.038711067289114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errRNN = eval(modelRNN)\n",
        "errLSTM = eval(modelLSTM)\n",
        "errGRU = eval(modelGRU)\n",
        "print('The final error of RNN is: {:.4f}'.format(errRNN))\n",
        "print('The final error of LSTM is: {:.4f}'.format(errLSTM))\n",
        "print('The final error of GRU is: {:.4f}'.format(errGRU))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzGwPnkgqgZy",
        "outputId": "f490a6a0-cce9-48e7-ba1a-15ee0b36eb0c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The final error of RNN is: 3.5953\n",
            "The final error of LSTM is: 7.5821\n",
            "The final error of GRU is: 2.8937\n"
          ]
        }
      ]
    }
  ]
}